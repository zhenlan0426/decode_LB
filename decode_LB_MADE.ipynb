{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5001 # number of observations in the LB\n",
    "T = 500 # number of submission \n",
    "batch = 20 \n",
    "p_y = 0.5 # prior distribution for y, true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission matrix. hyper-parameters\n",
    "Phat_uniform = np.random.rand(n,T)\n",
    "Phat_beta = np.maximum(np.minimum(beta.rvs(0.5,0.5,size=(n,T)),1-1e-4),1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeneratorFun(batch,Phat,p_y,nStandardScaler=5000):\n",
    "    # return a simulator for simulating Y and LB-scores\n",
    "    # nStandardScaler is the number of obs used to standardize score\n",
    "    n = Phat.shape[0]\n",
    "    logP = np.log(Phat)\n",
    "    log1_P = np.log(1-Phat)\n",
    "    Y = np.random.rand(nStandardScaler,n)>p_y\n",
    "    score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n    \n",
    "    mean_s, std_s = np.mean(score,0), np.std(score,0)\n",
    "    mean_y, std_y = np.mean(Y,0), np.std(Y,0)\n",
    "    def Generator():\n",
    "        Y = np.random.rand(batch,n)>p_y\n",
    "        score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n\n",
    "        score = (score - mean_s)/std_s\n",
    "        Y = (Y - mean_y)/std_y\n",
    "        return Y.astype(np.float32),score\n",
    "    return Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen1 = GeneratorFun(batch,Phat_uniform,p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build graph for masked autoencoder for distribution estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "epoch = 100\n",
    "depth = 3\n",
    "hiddenLayersShape = [T+n,2*n,n,n]\n",
    "actFun = [tf.nn.relu,tf.nn.relu,tf.nn.sigmoid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "score = tf.placeholder(tf.float32, [batch, T], name='score')\n",
    "Y = tf.placeholder(tf.float32, [batch, n], name='Y')\n",
    "masks = [tf.placeholder(tf.float32, [hiddenLayersShape[i],hiddenLayersShape[i+1]]) for i in range(depth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.concat([score,Y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(depth):\n",
    "    weights = tf.Variable(tf.truncated_normal([hiddenLayersShape[i],hiddenLayersShape[i+1]],\n",
    "                            stddev=1.0 / np.sqrt(hiddenLayersShape[i])),name='weights_'+str(i))\n",
    "    biases = tf.Variable(tf.zeros([hiddenLayersShape[i+1]]),\n",
    "                         name='biases_'+str(i))\n",
    "    X = actFun[i](tf.matmul(X, weights*masks[i]) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masks_np,masks_num = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_num.append(np.array(T*[0]+range(1,n+1)))\n",
    "low = 0\n",
    "high = n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(depth-1):\n",
    "    masks_num.append(np.random.randint(low,high,hiddenLayersShape[i+1]))\n",
    "    low = np.min(masks_num[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masks_num.append(np.array(range(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(depth):\n",
    "    masks_np.append((np.reshape(masks_num[i],[-1,1])<=masks_num[i+1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dict = {m:m_np for m,m_np in zip(masks,masks_np)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, Val loss:[0.73246992]\n",
      "iteration:10, Val loss:[0.69504511]\n",
      "iteration:20, Val loss:[0.69408321]\n",
      "iteration:30, Val loss:[0.69398314]\n",
      "iteration:40, Val loss:[0.69369155]\n",
      "iteration:50, Val loss:[0.69365662]\n",
      "iteration:60, Val loss:[0.69355166]\n",
      "iteration:70, Val loss:[0.69373757]\n",
      "iteration:80, Val loss:[0.69364828]\n",
      "iteration:90, Val loss:[0.6935277]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    y_np,score_np = gen1()\n",
    "    feed_dict = {score:score_np, Y:y_np}\n",
    "    feed_dict.update(base_dict)\n",
    "    _ = sess.run([train_op],feed_dict)\n",
    "\n",
    "    if i%10 == 0:\n",
    "        y_np,score_np = gen1()\n",
    "        feed_dict = {score:score_np, Y:y_np}\n",
    "        feed_dict.update(base_dict)\n",
    "        loss_val = sess.run([loss],feed_dict)\n",
    "\n",
    "        print \"iteration:{}, Val loss:{}\".format(i,loss_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
