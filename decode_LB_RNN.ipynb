{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5001 # number of observations in the LB\n",
    "T = 500 # number of submission \n",
    "batch = 20 \n",
    "p_y = 0.5 # prior distribution for y, true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission matrix. hyper-parameters\n",
    "Phat_uniform = np.random.rand(n,T)\n",
    "Phat_beta = np.maximum(np.minimum(beta.rvs(0.5,0.5,size=(n,T)),1-1e-4),1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeneratorFun(batch,Phat,p_y,nStandardScaler=5000):\n",
    "    # return a simulator for simulating Y and LB-scores\n",
    "    # nStandardScaler is the number of obs used to standardize score\n",
    "    n = Phat.shape[0]\n",
    "    logP = np.log(Phat)\n",
    "    log1_P = np.log(1-Phat)\n",
    "    Y = np.random.rand(nStandardScaler,n)>p_y\n",
    "    score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n    \n",
    "    mean_, std_ = np.mean(score,0), np.std(score,0)\n",
    "    def Generator():\n",
    "        Y = np.random.rand(batch,n)>p_y\n",
    "        score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n\n",
    "        score = (score - mean_)/std_\n",
    "        return Y.astype(np.float32),score\n",
    "    return Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_extractor(seq_len,n,Y):\n",
    "    # Generator generates the whole sequence. Have to chop it into seq_len segments for RNN\n",
    "    # n%seq_len needs to be 1 for this to work. otherwise needs to build a separate RNN graph \n",
    "    # with shorter length for static_rnn to work.\n",
    "    num = int(n/seq_len)\n",
    "    for i in range(num):\n",
    "        start,end = i*seq_len,(i+1)*seq_len\n",
    "        if end >= n:    \n",
    "            yield Y[:,start:n-1], Y[:,start+1:n]\n",
    "        else:\n",
    "            yield Y[:,start:end], Y[:,start+1:end+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen1 = GeneratorFun(batch,Phat_beta,p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,s = gen1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(s.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different model structure.\n",
    "1. skip connection between the score and every seq_len init via concat \n",
    "2. skip connection between the score and every seq_len init via addition\n",
    "3. no skip connection. Score fed in only at the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "cells_dim = 512\n",
    "learning_rate = 1e-3\n",
    "grad_clip = 10.0\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = tf.placeholder(tf.float32, [batch, T], name='score')\n",
    "X = tf.placeholder(tf.float32, [batch, seq_len], name='X')\n",
    "Y = tf.placeholder(tf.float32, [batch, seq_len], name='Y')\n",
    "keep_prob = tf.placeholder(tf.float32,[])\n",
    "is_start = tf.placeholder(tf.bool,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding = tf.get_variable(\"embedding\", [2, cells_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "# X_embed = tf.nn.relu(tf.nn.embedding_lookup(embedding,X))\n",
    "# X_list = tf.unstack(X_embed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list = tf.split(X,seq_len,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(cells_dim),keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_state = cell.zero_state(batch,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.concat score and init\n",
    "init_state2 = tf.concat([score,init_state],1)\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T+cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T+cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(init_state2, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    init_state2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.add score and init\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "    init_state2 = hidden2 + init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.no skip connection\n",
    "def MLP():\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights_h1 = tf.Variable(\n",
    "            tf.truncated_normal([T, cells_dim],\n",
    "                                stddev=1.0 / np.sqrt(T)),\n",
    "            name='weights')\n",
    "        biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                             name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights_h2 = tf.Variable(\n",
    "            tf.truncated_normal([cells_dim, cells_dim],\n",
    "                                stddev=1.0 / np.sqrt(cells_dim)),\n",
    "            name='weights')\n",
    "        biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                             name='biases')\n",
    "        hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "    return hidden2\n",
    "init_state2 = tf.cond(is_start, MLP, lambda: init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.no skip connection\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "init_state2 = tf.cond(is_start, lambda: hidden2, lambda: init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, state = tf.contrib.rnn.static_rnn(cell,X_list,init_state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_flat = tf.stack(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('prediction'):\n",
    "    weights_pred = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_pred = tf.Variable(tf.zeros([1,]),\n",
    "                         name='biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = tf.einsum('blc,c->bl',outputs_flat,weights_pred) + biases_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars),grad_clip)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build graph for sampling. There are two types of graph, one connected to score, one does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sample1 = tf.placeholder(tf.int32, [None], name='input_sample')\n",
    "state_sample1 = tf.placeholder(tf.float32, [None,cells_dim], name='input_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample1, state_out_sample1 = cell(tf.nn.embedding_lookup(embedding,input_sample1),state_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample1 = tf.nn.sigmoid(tf.einsum('bc,c->b',pred_sample1,weights_pred) + biases_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sample2 = tf.placeholder(tf.float32, [None, T], name='score')\n",
    "input_sample2 = tf.placeholder(tf.int32, [None], name='input_sample')\n",
    "state_sample2 = tf.placeholder(tf.float32, [None,cells_dim], name='input_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_sample2 = tf.concat([score_sample2,state_sample2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_sample1 = tf.nn.relu(tf.matmul(init_sample2, weights_h1) + biases_h1)\n",
    "hidden_sample2 = tf.nn.tanh(tf.matmul(hidden_sample1, weights_h2) + biases_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample2, state_out_sample2 = cell(tf.nn.embedding_lookup(embedding,input_sample2),hidden_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample2 = tf.nn.sigmoid(tf.einsum('bc,c->b',pred_sample2,weights_pred) + biases_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with skip connection\n",
    "for i in range(epoch):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    for y0,y1 in batch_extractor(seq_len,n,y_np):\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {score:score_np,X:y0,Y:y1,init_state:init_state_np,keep_prob:1})\n",
    "\n",
    "    if i%10 == 0:\n",
    "        init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "        loss_val = 0\n",
    "        y_np,score_np = gen1()\n",
    "        for j,(y0,y1) in enumerate(batch_extractor(seq_len,n,y_np)):\n",
    "            loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                              {score:score_np,X:y0,Y:y1,init_state:init_state_np,keep_prob:1})\n",
    "            loss_val += loss_j\n",
    "        loss_val /= j   \n",
    "\n",
    "        print \"iteration:{}, Val loss:{}\".format(i,loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no skip connection\n",
    "for i in range(epoch):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    extractor = batch_extractor(seq_len,n,y_np)\n",
    "    y0,y1 = extractor.next()\n",
    "    _,init_state_np = sess.run([train_op,state],\\\n",
    "                                      {score:score_np,init_state:init_state_np,X:y0,Y:y1,is_start:True,keep_prob:1})    \n",
    "    for y0,y1 in extractor:\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {X:y0,Y:y1,score:score_np,\\\n",
    "                                           init_state:init_state_np,keep_prob:1,\\\n",
    "                                          is_start:False})\n",
    "\n",
    "    if i%10 == 0:\n",
    "        init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "        loss_val = 0\n",
    "        y_np,score_np = gen1()\n",
    "        extractor = batch_extractor(seq_len,n,y_np)\n",
    "        y0,y1 = extractor.next()\n",
    "        loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                          {score:score_np,X:y0,Y:y1,init_state:init_state_np,\\\n",
    "                                           is_start:True,keep_prob:1})        \n",
    "        for j,(y0,y1) in enumerate(batch_extractor(seq_len,n,y_np)):\n",
    "            loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                              {score:score_np,X:y0,Y:y1,init_state:init_state_np,\\\n",
    "                                               is_start:False,keep_prob:1})\n",
    "            loss_val += loss_j\n",
    "        loss_val = loss_val/(j+1)   \n",
    "\n",
    "        print \"iteration:{}, Val loss:{}\".format(i,loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no skip connection\n",
    "for i in range(1):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    extractor = batch_extractor(seq_len,n,y_np)\n",
    "    y0,y1 = extractor.next()\n",
    "    print(sess.run([weights_h1])[0][0,0])\n",
    "    _,init_state_np = sess.run([train_op,state],\\\n",
    "                                      {score:score_np,init_state:init_state_np,X:y0,Y:y1,is_start:True,keep_prob:1})  \n",
    "    print(sess.run([weights_h1])[0][0,0])\n",
    "    for y0,y1 in extractor:\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {X:y0,Y:y1,score:score_np,\\\n",
    "                                           init_state:init_state_np,keep_prob:1,\\\n",
    "                                          is_start:False})\n",
    "        print(sess.run([weights_h1])[0][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
