{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5001 # number of observations in the LB\n",
    "T = 500 # number of submission \n",
    "batch = 20 \n",
    "p_y = 0.5 # prior distribution for y, true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission matrix. hyper-parameters\n",
    "Phat_uniform = np.random.rand(n,T)\n",
    "Phat_beta = np.maximum(np.minimum(beta.rvs(0.5,0.5,size=(n,T)),1-1e-4),1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeneratorFun(batch,Phat,p_y,nStandardScaler=5000):\n",
    "    # return a simulator for simulating Y and LB-scores\n",
    "    # nStandardScaler is the number of obs used to standardize score\n",
    "    n = Phat.shape[0]\n",
    "    logP = np.log(Phat)\n",
    "    log1_P = np.log(1-Phat)\n",
    "    Y = np.random.rand(nStandardScaler,n)>p_y\n",
    "    score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n    \n",
    "    mean_, std_ = np.mean(score,0), np.std(score,0)\n",
    "    def Generator():\n",
    "        Y = np.random.rand(batch,n)>p_y\n",
    "        score = (np.dot(Y,logP) + np.dot((1-Y),log1_P))/n\n",
    "        score = (score - mean_)/std_\n",
    "        return Y.astype(np.float32),score\n",
    "    return Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_extractor(seq_len,n,Y):\n",
    "    # Generator generates the whole sequence. Have to chop it into seq_len segments for RNN\n",
    "    # n%seq_len needs to be 1 for this to work. otherwise needs to build a separate RNN graph \n",
    "    # with shorter length for static_rnn to work.\n",
    "    num = int(n/seq_len)\n",
    "    for i in range(num):\n",
    "        start,end = i*seq_len,(i+1)*seq_len\n",
    "        if end >= n:    \n",
    "            yield Y[:,start:n-1], Y[:,start+1:n]\n",
    "        else:\n",
    "            yield Y[:,start:end], Y[:,start+1:end+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen1 = GeneratorFun(batch,Phat_beta,p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,s = gen1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  1.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  1.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   35.,   143.,   727.,  1741.,  2631.,  2505.,  1514.,   545.,\n",
       "          136.,    23.]),\n",
       " array([-3.4887724 , -2.77689409, -2.06501578, -1.35313747, -0.64125916,\n",
       "         0.07061915,  0.78249747,  1.49437578,  2.20625409,  2.9181324 ,\n",
       "         3.63001071]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD6BJREFUeJzt3X2o3vV5x/H3Z+qctJW1eCZpTBcH2ViUzWIIQstwuNVQ\nx2L/mERGdVRMi7a10LHFFma3ErBsbYdjylIUFVxdwBYD6lrrhK5/pPYorppY11AjJqQmfUJl4JZ4\n7Y/ztb17euK5z+PvnH7fL7i5v/f1e7ruhMPn/B5PqgpJUp9+ZegGJEnDMQQkqWOGgCR1zBCQpI4Z\nApLUMUNAkjpmCEhSxwwBSeqYISBJHTt16AZmc9ZZZ9X69euHbkOSVpXHH3/8B1U1Mdt8Kz4E1q9f\nz+Tk5NBtSNKqkuT5cebzcJAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHVs\nxd8xLM1m/Y4HBtnuwZsvG2S70mJyT0CSOmYISFLHDAFJ6pghIEkdMwQkqWOzhkCSdUkeTbI/yb4k\nN7T6p5IcTvJke713ZJkbkxxI8mySS0fqFyZ5qk27JUmW5mtJksYxziWix4GPV9UTSd4CPJ7k4Tbt\n81X1D6MzJ9kIbAPOA94OfC3Jb1fVCeA24Frgm8CDwBbgocX5KpKkuZp1T6CqjlTVE238MvAMsPYN\nFtkK3FtVr1bVc8ABYHOSNcCZVbW3qgq4G7h8wd9AkjRvczonkGQ98E6mfpMH+EiSbye5I8lbW20t\n8MLIYodabW0bT69LkgYy9h3DSd4M3Ad8rKpeSnIb8Gmg2vtngQ8sRlNJtgPbAd7xjncsxiqlRTfU\nncrg3cpaPGPtCSQ5jakAuKeqvgRQVS9W1Ymqeg34ArC5zX4YWDey+DmtdriNp9d/QVXtqqpNVbVp\nYmJiLt9HkjQH41wdFOB24Jmq+txIfc3IbO8Dnm7jPcC2JKcnORfYADxWVUeAl5Jc1NZ5FXD/In0P\nSdI8jHM46F3A+4GnkjzZap8ArkxyAVOHgw4CHwSoqn1JdgP7mbqy6Pp2ZRDAdcCdwBlMXRXklUGS\nNKBZQ6CqvgHMdD3/g2+wzE5g5wz1SeD8uTQoSVo63jEsSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CS\nOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKlj\nhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYI\nSFLHZg2BJOuSPJpkf5J9SW5o9bcleTjJd9v7W0eWuTHJgSTPJrl0pH5hkqfatFuSZGm+liRpHOPs\nCRwHPl5VG4GLgOuTbAR2AI9U1QbgkfaZNm0bcB6wBbg1ySltXbcB1wIb2mvLIn4XSdIczRoCVXWk\nqp5o45eBZ4C1wFbgrjbbXcDlbbwVuLeqXq2q54ADwOYka4Azq2pvVRVw98gykqQBzOmcQJL1wDuB\nbwJnV9WRNun7wNltvBZ4YWSxQ622to2n12fazvYkk0kmjx07NpcWJUlzMHYIJHkzcB/wsap6aXRa\n+82+FqupqtpVVZuqatPExMRirVaSNM1YIZDkNKYC4J6q+lIrv9gO8dDej7b6YWDdyOLntNrhNp5e\nlyQNZJyrgwLcDjxTVZ8bmbQHuLqNrwbuH6lvS3J6knOZOgH8WDt09FKSi9o6rxpZRpI0gFPHmOdd\nwPuBp5I82WqfAG4Gdie5BngeuAKgqvYl2Q3sZ+rKouur6kRb7jrgTuAM4KH2kiQNZNYQqKpvACe7\nnv+SkyyzE9g5Q30SOH8uDUqSlo53DEtSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6\nZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktSxcf6ojDSr9TseGLoFSfPgnoAkdcwQkKSO\nGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6tis\nIZDkjiRHkzw9UvtUksNJnmyv945MuzHJgSTPJrl0pH5hkqfatFuSZPG/jiRpLsbZE7gT2DJD/fNV\ndUF7PQiQZCOwDTivLXNrklPa/LcB1wIb2mumdUqSltGsIVBVXwd+NOb6tgL3VtWrVfUccADYnGQN\ncGZV7a2qAu4GLp9v05KkxbGQvyz2kSRXAZPAx6vqx8BaYO/IPIda7f/aeHpd0jwM9ZfcDt582SDb\n1dKZ74nh24DfAi4AjgCfXbSOgCTbk0wmmTx27NhirlqSNGJeIVBVL1bViap6DfgCsLlNOgysG5n1\nnFY73MbT6ydb/66q2lRVmyYmJubToiRpDPMKgXaM/3XvA16/cmgPsC3J6UnOZeoE8GNVdQR4KclF\n7aqgq4D7F9C3JGkRzHpOIMkXgYuBs5IcAm4CLk5yAVDAQeCDAFW1L8luYD9wHLi+qk60VV3H1JVG\nZwAPtZckaUCzhkBVXTlD+fY3mH8nsHOG+iRw/py6kyQtKe8YlqSOGQKS1DFDQJI6ZghIUscMAUnq\nmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4Z\nApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEg\nSR2bNQSS3JHkaJKnR2pvS/Jwku+297eOTLsxyYEkzya5dKR+YZKn2rRbkmTxv44kaS7G2RO4E9gy\nrbYDeKSqNgCPtM8k2QhsA85ry9ya5JS2zG3AtcCG9pq+TknSMps1BKrq68CPppW3Ane18V3A5SP1\ne6vq1ap6DjgAbE6yBjizqvZWVQF3jywjSRrIfM8JnF1VR9r4+8DZbbwWeGFkvkOttraNp9clSQNa\n8Inh9pt9LUIvP5Vke5LJJJPHjh1bzFVLkkbMNwRebId4aO9HW/0wsG5kvnNa7XAbT6/PqKp2VdWm\nqto0MTExzxYlSbOZbwjsAa5u46uB+0fq25KcnuRcpk4AP9YOHb2U5KJ2VdBVI8tIkgZy6mwzJPki\ncDFwVpJDwE3AzcDuJNcAzwNXAFTVviS7gf3AceD6qjrRVnUdU1canQE81F6SpAHNGgJVdeVJJl1y\nkvl3AjtnqE8C58+pO0nSkvKOYUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ\n6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSerYrH9ZTKvL+h0PDN2CpFXEPQFJ\n6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSO\nLegpokkOAi8DJ4DjVbUpyduAfwPWAweBK6rqx23+G4Fr2vwfraqvLGT7kpbXUE+pPXjzZYNstweL\nsSfwh1V1QVVtap93AI9U1QbgkfaZJBuBbcB5wBbg1iSnLML2JUnztBSHg7YCd7XxXcDlI/V7q+rV\nqnoOOABsXoLtS5LGtNAQKOBrSR5Psr3Vzq6qI238feDsNl4LvDCy7KFW+wVJtieZTDJ57NixBbYo\nSTqZhf5lsXdX1eEkvwE8nOQ7oxOrqpLUXFdaVbuAXQCbNm2a8/KSpPEsaE+gqg6396PAl5k6vPNi\nkjUA7f1om/0wsG5k8XNaTZI0kHmHQJI3JXnL62PgPcDTwB7g6jbb1cD9bbwH2Jbk9CTnAhuAx+a7\nfUnSwi3kcNDZwJeTvL6ef62qf0/yLWB3kmuA54ErAKpqX5LdwH7gOHB9VZ1YUPeSpAWZdwhU1feA\n35+h/kPgkpMssxPYOd9tSpIWl3cMS1LHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpm\nCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aA\nJHXMEJCkjhkCktSxU4du4JfR+h0PDN2C9EtlyJ+pgzdfNti2l4N7ApLUMUNAkjpmCEhSxwwBSeqY\nISBJHTMEJKljyx4CSbYkeTbJgSQ7lnv7kqSfWdb7BJKcAvwz8MfAIeBbSfZU1f6l2J7X60vSG1vu\nm8U2Aweq6nsASe4FtgJLEgKStFBD/TK5XDepLffhoLXACyOfD7WaJGkAK/KxEUm2A9vbx1eSPDtk\nP9OcBfxg6CbGtFp6XS19gr0uldXS67L1mc8seBW/Oc5Myx0Ch4F1I5/PabWfU1W7gF3L1dRcJJms\nqk1D9zGO1dLraukT7HWprJZeV0ufc7Hch4O+BWxIcm6SXwW2AXuWuQdJUrOsewJVdTzJh4GvAKcA\nd1TVvuXsQZL0M8t+TqCqHgQeXO7tLqIVeZjqJFZLr6ulT7DXpbJael0tfY4tVTV0D5KkgfjYCEnq\nmCEwD0k+neTbSZ5M8tUkbx+6p5kk+fsk32m9fjnJrw/d08kk+bMk+5K8lmRFXn2xWh55kuSOJEeT\nPD10L28kybokjybZ3/7vbxi6p5NJ8mtJHkvyX63Xvx26p8Xi4aB5SHJmVb3Uxh8FNlbVhwZu6xck\neQ/wH+2E/GcAquqvB25rRkl+F3gN+BfgL6tqcuCWfk575Ml/M/LIE+DKpXrkyUIk+QPgFeDuqjp/\n6H5OJskaYE1VPZHkLcDjwOUr9N80wJuq6pUkpwHfAG6oqr0Dt7Zg7gnMw+sB0LwJWJFJWlVfrarj\n7eNepu7LWJGq6pmqWkk3BU7300eeVNX/Aq8/8mTFqaqvAz8auo/ZVNWRqnqijV8GnmGFPkGgprzS\nPp7WXivy536uDIF5SrIzyQvAnwN/M3Q/Y/gA8NDQTaxiPvJkCSVZD7wT+OawnZxcklOSPAkcBR6u\nqhXb61wYAieR5GtJnp7htRWgqj5ZVeuAe4APr9Q+2zyfBI63XgczTq/qT5I3A/cBH5u2l72iVNWJ\nqrqAqT3qzUlW7KG2uViRzw5aCarqj8ac9R6m7nu4aQnbOanZ+kzyF8CfAJfUwCeA5vBvuhKN9cgT\nzU07vn4fcE9VfWnofsZRVT9J8iiwBVjRJ9/H4Z7APCTZMPJxK/CdoXp5I0m2AH8F/GlV/c/Q/axy\nPvJkkbWTrbcDz1TV54bu540kmXj96rokZzB1gcCK/LmfK68Omock9wG/w9TVLM8DH6qqFfdbYZID\nwOnAD1tp70q8igkgyfuAfwImgJ8AT1bVpcN29fOSvBf4R372yJOdA7c0oyRfBC5m6omXLwI3VdXt\ngzY1gyTvBv4TeIqpnyWAT7SnCqwoSX4PuIup//tfAXZX1d8N29XiMAQkqWMeDpKkjhkCktQxQ0CS\nOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR17P8BZSdArDeNussAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f118ea4c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(s.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different model structure.\n",
    "1. skip connection between the score and every seq_len init via concat \n",
    "2. skip connection between the score and every seq_len init via addition\n",
    "3. no skip connection. Score fed in only at the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "cells_dim = 512\n",
    "learning_rate = 1e-3\n",
    "grad_clip = 10.0\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = tf.placeholder(tf.float32, [batch, T], name='score')\n",
    "X = tf.placeholder(tf.float32, [batch, seq_len], name='X')\n",
    "Y = tf.placeholder(tf.float32, [batch, seq_len], name='Y')\n",
    "keep_prob = tf.placeholder(tf.float32,[])\n",
    "is_start = tf.placeholder(tf.bool,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding = tf.get_variable(\"embedding\", [2, cells_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "# X_embed = tf.nn.relu(tf.nn.embedding_lookup(embedding,X))\n",
    "# X_list = tf.unstack(X_embed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list = tf.split(X,seq_len,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(cells_dim),keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_state = cell.zero_state(batch,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.concat score and init\n",
    "init_state2 = tf.concat([score,init_state],1)\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T+cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T+cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(init_state2, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    init_state2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.add score and init\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "    init_state2 = hidden2 + init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.no skip connection\n",
    "def MLP():\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights_h1 = tf.Variable(\n",
    "            tf.truncated_normal([T, cells_dim],\n",
    "                                stddev=1.0 / np.sqrt(T)),\n",
    "            name='weights')\n",
    "        biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                             name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights_h2 = tf.Variable(\n",
    "            tf.truncated_normal([cells_dim, cells_dim],\n",
    "                                stddev=1.0 / np.sqrt(cells_dim)),\n",
    "            name='weights')\n",
    "        biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                             name='biases')\n",
    "        hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "    return hidden2\n",
    "init_state2 = tf.cond(is_start, MLP, lambda: init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.no skip connection\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(\n",
    "        tf.truncated_normal([T, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(T)),\n",
    "        name='weights')\n",
    "    biases_h1 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(score, weights_h1) + biases_h1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim, cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_h2 = tf.Variable(tf.zeros([cells_dim]),\n",
    "                         name='biases')\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights_h2) + biases_h2) # use tanh to be in the same range as GRU\n",
    "init_state2 = tf.cond(is_start, lambda: hidden2, lambda: init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, state = tf.contrib.rnn.static_rnn(cell,X_list,init_state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_flat = tf.stack(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('prediction'):\n",
    "    weights_pred = tf.Variable(\n",
    "        tf.truncated_normal([cells_dim],\n",
    "                            stddev=1.0 / np.sqrt(cells_dim)),\n",
    "        name='weights')\n",
    "    biases_pred = tf.Variable(tf.zeros([1,]),\n",
    "                         name='biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tf.einsum('blc,c->bl',outputs_flat,weights_pred) + biases_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars),grad_clip)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build graph for sampling. There are two types of graph, one connected to score, one does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sample1 = tf.placeholder(tf.int32, [None], name='input_sample')\n",
    "state_sample1 = tf.placeholder(tf.float32, [None,cells_dim], name='input_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample1, state_out_sample1 = cell(tf.nn.embedding_lookup(embedding,input_sample1),state_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample1 = tf.nn.sigmoid(tf.einsum('bc,c->b',pred_sample1,weights_pred) + biases_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sample2 = tf.placeholder(tf.float32, [None, T], name='score')\n",
    "input_sample2 = tf.placeholder(tf.int32, [None], name='input_sample')\n",
    "state_sample2 = tf.placeholder(tf.float32, [None,cells_dim], name='input_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_sample2 = tf.concat([score_sample2,state_sample2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_sample1 = tf.nn.relu(tf.matmul(init_sample2, weights_h1) + biases_h1)\n",
    "hidden_sample2 = tf.nn.tanh(tf.matmul(hidden_sample1, weights_h2) + biases_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample2, state_out_sample2 = cell(tf.nn.embedding_lookup(embedding,input_sample2),hidden_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sample2 = tf.nn.sigmoid(tf.einsum('bc,c->b',pred_sample2,weights_pred) + biases_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, Val loss:0.707361155627\n",
      "iteration:10, Val loss:0.707416309386\n",
      "iteration:20, Val loss:0.707302420723\n",
      "iteration:30, Val loss:0.707305762233\n",
      "iteration:40, Val loss:0.707301184839\n",
      "iteration:50, Val loss:0.707316014231\n",
      "iteration:60, Val loss:0.707280253877\n",
      "iteration:70, Val loss:0.707301166593\n",
      "iteration:80, Val loss:0.707296322803\n",
      "iteration:90, Val loss:0.70730457014\n"
     ]
    }
   ],
   "source": [
    "# with skip connection\n",
    "for i in range(epoch):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    for y0,y1 in batch_extractor(seq_len,n,y_np):\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {score:score_np,X:y0,Y:y1,init_state:init_state_np,keep_prob:1})\n",
    "\n",
    "    if i%10 == 0:\n",
    "        init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "        loss_val = 0\n",
    "        y_np,score_np = gen1()\n",
    "        for j,(y0,y1) in enumerate(batch_extractor(seq_len,n,y_np)):\n",
    "            loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                              {score:score_np,X:y0,Y:y1,init_state:init_state_np,keep_prob:1})\n",
    "            loss_val += loss_j\n",
    "        loss_val /= j   \n",
    "\n",
    "        print \"iteration:{}, Val loss:{}\".format(i,loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, Val loss:0.696341665983\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-286ce8d5e588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_state_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0;34m{\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscore_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minit_state_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_state_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                          \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscore_np\u001b[0m\u001b[0;34m,\u001b[0m                                           \u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minit_state_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                                          \u001b[0mis_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no skip connection\n",
    "for i in range(epoch):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    extractor = batch_extractor(seq_len,n,y_np)\n",
    "    y0,y1 = extractor.next()\n",
    "    _,init_state_np = sess.run([train_op,state],\\\n",
    "                                      {score:score_np,init_state:init_state_np,X:y0,Y:y1,is_start:True,keep_prob:1})    \n",
    "    for y0,y1 in extractor:\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {X:y0,Y:y1,score:score_np,\\\n",
    "                                           init_state:init_state_np,keep_prob:1,\\\n",
    "                                          is_start:False})\n",
    "\n",
    "    if i%10 == 0:\n",
    "        init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "        loss_val = 0\n",
    "        y_np,score_np = gen1()\n",
    "        extractor = batch_extractor(seq_len,n,y_np)\n",
    "        y0,y1 = extractor.next()\n",
    "        loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                          {score:score_np,X:y0,Y:y1,init_state:init_state_np,\\\n",
    "                                           is_start:True,keep_prob:1})        \n",
    "        for j,(y0,y1) in enumerate(batch_extractor(seq_len,n,y_np)):\n",
    "            loss_j,init_state_np = sess.run([loss,state],\\\n",
    "                                              {score:score_np,X:y0,Y:y1,init_state:init_state_np,\\\n",
    "                                               is_start:False,keep_prob:1})\n",
    "            loss_val += loss_j\n",
    "        loss_val = loss_val/(j+1)   \n",
    "\n",
    "        print \"iteration:{}, Val loss:{}\".format(i,loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0273087\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"X:0\", shape=(20, 100), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-23ca747ede46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights_h1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_state_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0;34m{\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscore_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minit_state_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights_h1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/will/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    943\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 945\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"X:0\", shape=(20, 100), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "# no skip connection\n",
    "for i in range(1):\n",
    "    init_state_np = np.zeros((batch,cells_dim),dtype=np.float32)\n",
    "    y_np,score_np = gen1()\n",
    "    extractor = batch_extractor(seq_len,n,y_np)\n",
    "    y0,y1 = extractor.next()\n",
    "    print(sess.run([weights_h1])[0][0,0])\n",
    "    _,init_state_np = sess.run([train_op,state],\\\n",
    "                                      {score:score_np,init_state:init_state_np,X:y0,Y:y1,is_start:True,keep_prob:1})  \n",
    "    print(sess.run([weights_h1])[0][0,0])\n",
    "    for y0,y1 in extractor:\n",
    "        _,init_state_np = sess.run([train_op,state],\\\n",
    "                                          {X:y0,Y:y1,score:score_np,\\\n",
    "                                           init_state:init_state_np,keep_prob:1,\\\n",
    "                                          is_start:False})\n",
    "        print(sess.run([weights_h1])[0][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
